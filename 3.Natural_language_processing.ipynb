{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Natural Language Processing\n",
    "### 1. Preprocessing the documents for analysis\n",
    "#### 1. Tokenize\n",
    "* First we split the lyrics in two datasets, one for training and one for testing.\n",
    "* For now we will work with the training set. We use gensims simple_preprocess function, to convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "lyrics = pd.read_csv('../dataset/Lyrics_en.csv', index_col=['Band'])\n",
    "genres = pd.read_csv('../dataset/artists_final_ohe.csv', index_col=['Band'])\n",
    "df = pd.merge(lyrics, genres, on=['Band'])\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train.to_csv('../dataset/Lyrics_en_artists_clean_train.csv')\n",
    "test.to_csv('../dataset/Lyrics_en_artists_clean_test.csv')\n",
    "del train\n",
    "del test\n",
    "\n",
    "df = pd.read_csv('../dataset/Lyrics_en_artists_clean_train.csv')\n",
    "for index, row in df.iterrows():\n",
    "    lyric = row[1]\n",
    "    newLyric = gensim.utils.simple_preprocess(str(lyric), deacc=True)\n",
    "    df.at[index, 'Lyrics'] = newLyric\n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create bigrams and trigrams models\n",
    "Use gensim Phraser to detect phrases, a phrase is a token formed by two (bigram) or more words. \n",
    "\n",
    "For example New and York may appear together very often, this process will detect them and join them as a single token New_York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "lyrics = list()\n",
    "for i in range(0, df.shape[0]):\n",
    "    lyric = df.iloc[i][1]\n",
    "    lyrics.append(lyric)\n",
    "    \n",
    "bi_prhases = Phrases(lyrics, min_count=5, threshold=40)\n",
    "tri_prhases = Phrases(bi_prhases[lyrics], threshold=40)  \n",
    "\n",
    "bigram = Phraser(bi_prhases)\n",
    "trigram = Phraser(tri_prhases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Remove stop words\n",
    "There are words that have no meaning to our dataset. We use nltk stop words, add a couple of words (s and chorus) and then remove them from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jescobedo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['s', 'chorus'])\n",
    "\n",
    "new_lyrics = list()\n",
    "for lyric in lyrics:\n",
    "    new_lyric = list()\n",
    "    for word in lyric:\n",
    "        if(word not in stop_words):\n",
    "            new_lyric.append(word)\n",
    "    new_lyrics.append(new_lyric)\n",
    "    \n",
    "#print(lyrics[0])\n",
    "#print(new_lyrics[0])\n",
    "lyrics = new_lyrics\n",
    "del new_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Lemmatize words\n",
    "The are words that have no meaning, removed in previous step, but there are words with the same meaning as others (e.g. am, are, is = be). This time we use spacy to transform these words, only keeping nouns, adjetives, verbs and adverbs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_lyrics = list()\n",
    "for lyric in lyrics:\n",
    "    bigram_lyrics.append(bigram[lyric])\n",
    "lyrics = bigram_lyrics\n",
    "del bigram_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['have', 'give', 'life', 'decadent', 'goal', 'bless', 'look', 'eye', 'repent', 'mass', 'night', 'sex', 'sinister', 'prize', 'beg', 'get', 'knee', 'pray', 'well', 'all', 'cast', 'first', 'stone', 'pride', 'lust', 'whore', 'night', 'drown', 'pleasure', 'inhale', 'love', 'bring', 'hatred', 'lie', 'await', 'indulgence', 'find', 'home', 'bear', 'blasphemer', 'die', 'cry', 'soul', 'damn', 'sky', 'communion', 'longer', 'suffice', 'flame', 'rise', 'demise', 'confession', 'lie']]\n"
     ]
    }
   ],
   "source": [
    "del lemma_lyricsimport spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "# python -m spacy download en\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
    "\n",
    "allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "lemma_lyrics = list()\n",
    "for lyric in lyrics:\n",
    "    doc = nlp(\" \".join(lyric)) \n",
    "    lemma_lyric = list()\n",
    "    for token in doc:\n",
    "        if(token.pos_ in allowed_postags):\n",
    "            lemma_lyric.append(token.lemma_)\n",
    "    lemma_lyrics.append(lemma_lyric)\n",
    "\n",
    "\n",
    "print(lemma_lyrics[:1])\n",
    "lyrics = lemma_lyrics\n",
    "\n",
    "del lemma_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lemma_lyrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4944ed4efd44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#SAVE LYRICS to disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../dataset/lemma_lyrics_train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemma_lyrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lemma_lyrics' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "#SAVE LYRICS to disk\n",
    "with open('../dataset/lemma_lyrics_train', 'wb') as fp:\n",
    "    pickle.dump(lyrics, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(lyrics.size == df.shape[0]):\n",
    "    print(\"Equal size\")\n",
    "    for index, lyric in lyrics:\n",
    "        df.at[index, 'Lyrics'] = lyric\n",
    "del lyrics\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = df.groupby(['Band']).sum().reset_index(drop=True).sum()\n",
    "print(genres.describe())\n",
    "genres.sort_values().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "big_genres = set()\n",
    "for index,genre_sum in genres.iteritems():\n",
    "    if(genre_sum > 50000):\n",
    "        big_genres.add(index)\n",
    "\n",
    "new_list = list()\n",
    "for index,row in df.iterrows():\n",
    "    expand = True\n",
    "    for big_genre in big_genres:\n",
    "        if(df[big_genre].iloc[index] == 1):\n",
    "            expand = False\n",
    "    if(expand):\n",
    "        newRow = row.to_dict()\n",
    "        ly = newRow['Lyrics'].split('\\r\\r\\n\\r\\r\\n')\n",
    "        random.shuffle(ly, random.random)\n",
    "        newLy = ''\n",
    "        for paragraph in ly:\n",
    "            newLy += paragraph + \"\\r\\r\\n\\r\\r\\n\"\n",
    "        newRow['Lyrics'] = newLy\n",
    "        new_list.append(newRow)\n",
    "new_df = pd.DataFrame(new_list, columns=df.columns)\n",
    "df = df.append(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words = list()\n",
    "for lyric in lyrics:\n",
    "    for word in lyric:\n",
    "        words.append(word)\n",
    "\n",
    "word_freq = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x231bd5aedd8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.DataFrame.from_dict(word_freq.most_common(20))\n",
    "df.plot(x=0, kind ='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Words representation\n",
    "#### 1. BOW and Tf-idf\n",
    "\n",
    "* Using gensim's corpora we create a dictionary. A dictionary is the mapping of each word to an id.\n",
    "* With this dictionary we create a bag of words **(BOW)** for each document, which is a list of tuples, with information of each token id (from the dictionary) and the number of times it appears in each document.\n",
    "* Finally with the **BOWs** we create a term frequency - inverse document frequency model **(Tf-Idf)**, this model transforms each word frequency to its importance score in every document. The bigger the number, the more common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanp\\Anaconda3\\envs\\mlnd\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 1), (2, 1), (3, 13), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 3), (15, 3), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 45), (23, 1), (24, 3), (25, 3), (26, 1), (27, 5), (28, 1), (29, 6), (30, 1), (31, 1), (32, 1), (33, 4), (34, 3), (35, 1), (36, 1), (37, 1), (38, 4), (39, 1), (40, 2), (41, 1), (42, 2), (43, 2), (44, 6), (45, 1), (46, 1), (47, 2), (48, 7), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 3), (56, 3), (57, 1), (58, 5), (59, 2), (60, 2), (61, 3), (62, 1), (63, 1), (64, 1), (65, 3), (66, 3), (67, 2), (68, 1), (69, 1), (70, 1), (71, 2), (72, 3), (73, 2), (74, 3), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1)]\n",
      "[(0, 0.05693230226707338), (1, 0.027704914478609205), (2, 0.04549673720943144), (3, 0.0289448229988323), (4, 0.015806998693867935), (5, 0.024025594355196165), (6, 0.023098009819700793), (7, 0.025811526273479265), (8, 0.010569261638354028), (9, 0.006612118130594775), (10, 0.024434477822771413), (11, 0.023239054344131573), (12, 0.023722253815393342), (13, 0.01746168238834378), (14, 0.03560056560150568), (15, 0.011175632466044262), (16, 0.041336779512986775), (17, 0.009684581016985033), (18, 0.0196937108111364), (19, 0.01863926550962034), (20, 0.0104411446409335), (21, 0.015887644537269954), (22, 0.9396869092284773), (23, 0.013589339666032917), (24, 0.1196295668814131), (25, 0.0460039955943677), (26, 0.02065652711263163), (27, 0.018940556086540477), (28, 0.01183726099719727), (29, 0.03533833104995298), (30, 0.009053608324670726), (31, 0.038302865707757615), (32, 0.01707644348539919), (33, 0.01370690679068628), (34, 0.02326870491647565), (35, 0.015390626768264403), (36, 0.016202881585968113), (37, 0.01037971421230309), (38, 0.016704079898947965), (39, 0.008771906754754038), (40, 0.029158288079345823), (41, 0.036948967242739675), (42, 0.025429595408602717), (43, 0.012316686718366264), (44, 0.10577675169825852), (45, 0.01914790751556941), (46, 0.04185410282357955), (47, 0.03278591441456118), (48, 0.014513661570347204), (49, 0.051946087517519654), (50, 0.011759345121925073), (51, 0.02760764927409373), (52, 0.03834916742194089), (53, 0.01617579192795459), (54, 0.04060944616378216), (55, 0.10119874676478062), (56, 0.06207826862031278), (57, 0.021805178747774333), (58, 0.025182746157760626), (59, 0.010303784791465263), (60, 0.009696437119073375), (61, 0.04705135768423608), (62, 0.021500696602689894), (63, 0.030797539868036173), (64, 0.01482457817346039), (65, 0.12668890417802453), (66, 0.05008447692209673), (67, 0.022994154101569197), (68, 0.03033245410856555), (69, 0.011583291476367153), (70, 0.018765383340852065), (71, 0.039384749934122054), (72, 0.06628042421042103), (73, 0.021153362352086712), (74, 0.07831232337281911), (75, 0.023552487971946628), (76, 0.012776946014695416), (77, 0.012764600383873111), (78, 0.03703880208951916), (79, 0.012915065105224102)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "id2word = corpora.Dictionary(lyrics)\n",
    "id2word.save(\"../dataset/lemma_lyrics_train_dict\")\n",
    "\n",
    "bow_corpus = list()\n",
    "\n",
    "for lyric in lyrics:\n",
    "    bow_corpus.append(id2word.doc2bow(lyric))\n",
    "\n",
    "tfidf = TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf[bow_corpus]\n",
    "print(bow_corpus[0])\n",
    "print(tfidf_corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Word2Vec\n",
    "* Word2Vec transforms a collection of documents and produces a vector space of each word.\n",
    "* These vector are close to the vectors that are common to them.\n",
    "* Word2Vec is a neural network of two dimmensions\n",
    "* Here we use the continuos bag of word (CBOW) algorithm, that tries to predict a word based on its context. This is useful since skip-gram instead tries to predict the context, making it slower but more accurate on infrequent words. In our case, musicians have a small vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(lyrics, workers=4, iter=3)\n",
    "word_vectors = word2vec.wv\n",
    "word2vec.save(\"../dataset/word2vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see the most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loving', 0.7502729296684265),\n",
       " ('baby', 0.6895380020141602),\n",
       " ('true', 0.6719269752502441),\n",
       " ('know', 0.666519284248352),\n",
       " ('darling', 0.6553927659988403),\n",
       " ('unconditional', 0.6393495798110962),\n",
       " ('want', 0.6328312754631042),\n",
       " ('heart', 0.6235368251800537),\n",
       " ('darlin', 0.6204294562339783),\n",
       " ('give', 0.6028942465782166)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jealousy', 0.5478307604789734),\n",
       " ('envy', 0.5122020840644836),\n",
       " ('suffer', 0.5009539723396301),\n",
       " ('relate', 0.4845621585845947),\n",
       " ('hatred', 0.4722989797592163),\n",
       " ('hater', 0.47106990218162537),\n",
       " ('anger', 0.4707857072353363),\n",
       " ('tolerate', 0.4615577161312103),\n",
       " ('debate', 0.4562164843082428),\n",
       " ('worst_enemy', 0.45264697074890137)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('holy', 0.6329371929168701),\n",
       " ('bless', 0.6200424432754517),\n",
       " ('almighty', 0.6178418397903442),\n",
       " ('lord', 0.6115849018096924),\n",
       " ('pray', 0.6114975810050964),\n",
       " ('blessed', 0.5861982107162476),\n",
       " ('grace', 0.581980288028717),\n",
       " ('savior', 0.5815690755844116),\n",
       " ('forgif', 0.5763567686080933),\n",
       " ('saviour', 0.5717598795890808)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"god\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bark', 0.721328616142273),\n",
       " ('cat', 0.6756749153137207),\n",
       " ('leash', 0.5832235813140869),\n",
       " ('woof', 0.5778262615203857),\n",
       " ('buying_chihuahua', 0.543731689453125),\n",
       " ('waggin', 0.5247211456298828),\n",
       " ('hog', 0.523919939994812),\n",
       " ('wolf', 0.5199141502380371),\n",
       " ('doggy', 0.5101379156112671),\n",
       " ('kennel', 0.48979413509368896)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Doc2Vec\n",
    "* This model adds an extra description to the Word2Vec model, this model also adds a representation related to the document, not only the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "tagged_lyrics = [TaggedDocument(lyric, [i]) for i, lyric in enumerate(lyrics)]\n",
    "\n",
    "doc2vec = Doc2Vec(tagged_lyrics, workers=4, epochs=3)\n",
    "doc_vectors = doc2vec.docvecs\n",
    "\n",
    "doc2vec.save(\"../dataset/doc2vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the most similar documents to the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'think', 'would', 'fall', 'hear', 'love', 'call', 'be', 'get', 'sentimental', 'thing', 'say', 'thrill', 'be', 'get', 'sentimental', 'thought', 'happy', 'could', 'live', 'love', 'must', 'admit', 'love', 'be', 'think', 'will', 'not', 'kind', 'make', 'mind', 'will', 'sweet', 'gentle', 'gentle', 'be', 'sentimental'] 0.6838473081588745 298879\n",
      "['want', 'need', 'know', 'way', 'up', 'turnaround', 'know', 'feel', 'somehow', 'seem', 'find', 'mind', 'sunshine', 'horizon', 'know', 'feel', 'call', 'restore', 'know', 'feeling', 'somehow', 'seem', 'find', 'mind', 'rise', 'fall', 'call', 'look', 'eye', 'rise', 'fall', 'call', 'look', 'eye', 'see', 'smile', 'know', 'rise', 'fall', 'tonight', 'fine', 'line', 'light', 'shin', 'good', 'feeling', 'need', 'share', 'feeling', 'somehow', 'seem', 'find', 'mind', 'rise', 'fall', 'call', 'look', 'eye', 'rise', 'fall', 'call', 'look', 'eye', 'see', 'smile', 'know', 'rise', 'fall', 'tonight'] 0.6711493730545044 201502\n",
      "['pretty', 'eye', 'pretty', 'eye', 'cloud', 'day', 'cloud', 'way', 'angel', 'eye', 'disguise', 'pretention', 'pretention', 'fear', 'do', 'not', 'leave', 'call', 'do', 'not', 'leave', 'fall', 'do', 'not', 'leave', 'call', 'do', 'not', 'leave', 'fall', 'stay', 'awhile', 'stay', 'awhile', 'tell', 'mind', 'tell', 'mind', 'kill', 'everything', 'take', 'pain', 'take', 'pain', 'do', 'not', 'leave', 'call', 'do', 'not', 'leave', 'fall', 'do', 'not', 'leave', 'call', 'do', 'not', 'leave', 'fall'] 0.6624482870101929 256001\n",
      "['thing', 'call', 'love', 'funny', 'thing', 'call', 'love', 'solve', 'mystery', 'make', 'fool', 'see', 'wonderful', 'day', 'take', 'heart', 'throw', 'away', 'ask', 'lord', 'heaven', 'thing', 'call', 'love'] 0.6592307090759277 261062\n",
      "['have', 'get', 'lift', 'high', 'can', 'not', 'see', 'ground', 'do', 'not', 'hear', 'sound', 'have', 'get', 'move', 'slow', 'see', 'will', 'probably', 'fall', 'id_rather', 'die', 'see', 'fly', 'try', 'id_rather', 'die', 'see', 'fly', 'try', 'push', 'lock', 'door', 'get', 'mind', 'do', 'not', 'care', 'find', 'push', 'lock', 'door', 'get', 'mind', 'do', 'not', 'know', 'ill', 'find', 'have', 'get', 'move', 'high', 'hurt', 'high', 'burn', 'let', 'do', 'not', 'bother', 'call', 'let', 'fall', 'id_rather', 'die', 'see', 'fly', 'try', 'id_rather', 'die', 'see', 'fly', 'try', 'push', 'lock', 'door', 'get', 'mind', 'do', 'not', 'know', 'ill', 'find', 'push', 'lock', 'door', 'get', 'mind', 'do', 'not', 'care', 'find', 'push', 'lock', 'door', 'get', 'mind', 'do', 'not', 'care', 'find', 'push', 'lock', 'door', 'get', 'mind', 'do', 'not', 'care', 'find', 'push', 'lock', 'door', 'get', 'mind', 'do', 'not', 'care', 'find', 'push', 'lock', 'get', 'mind', 'do', 'not', 'care', 'find', 'push', 'lock', 'door', 'get', 'mind', 'do', 'not', 'care', 'find', 'way', 'go', 'way', 'go', 'way', 'go', 'way', 'go'] 0.6562390923500061 193547\n"
     ]
    }
   ],
   "source": [
    "new_vector = doc2vec.infer_vector(['never', 'think', 'would', 'fall', 'hear', 'love', 'call', 'be', 'get', 'sentimental', 'thing'])\n",
    "sims = doc_vectors.most_similar([new_vector], topn=5)\n",
    "for sim in sims:\n",
    "    print(lyrics[sim[0]], sim[1], sim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cover', 'waterfront', 'be', 'watch', 'sea', 'love', 'come', 'back', 'cover', 'waterfront', 'search', 'love', 'be', 'cover', 'patiently', 'wait', 'hop', 'longing', 'yearn', 'forget', 'remember', 'return', 'cover', 'waterfront', 'be', 'watch', 'sea', 'love', 'must', 'come', 'back'] 0.8228856921195984\n",
      "['chestnuts_roast', 'open', 'fire', 'jack_frost', 'nip', 'nose_yuletide', 'carol', 'sing', 'choir', 'folk', 'dress', 'eskimos_everybody', 'knows_turkey', 'mistletoe', 'help', 'make', 'season', 'bright', 'tiny_tot', 'eye', 'aglow', 'find', 'hard', 'sleep', 'tonight', 'know', 'santa', 'way', 'loaded_lot', 'toy', 'goody', 'sleigh', 'mother', 'child', 'go', 'spy', 'see', 'reindeer', 'really', 'know', 'fly', 'be', 'offer', 'simple_phrase', 'kid', 'say', 'many', 'time', 'many', 'way', 'merry_christma', 'know', 'santa', 'way', 'toy', 'goody', 'sleigh', 'mother', 'child', 'go', 'spy', 'see', 'reindeer', 'really', 'know', 'fly', 'be', 'offer', 'simple_phrase', 'kid', 'say', 'many', 'time', 'many', 'way', 'merry_christma'] 0.8196104168891907\n",
      "['good', 'morning', 'good', 'morning', 'wake', 'time', 'get', 'wake', 'good', 'morning', 'be', 'wake', 'big', 'smile', 'face', 'keep', 'smile', 'today', 'go', 'good', 'day', 'life'] 0.8154854774475098\n",
      "['never', 'think', 'would', 'fall', 'hear', 'love', 'call', 'be', 'get', 'sentimental', 'thing', 'say', 'thrill', 'be', 'get', 'sentimental', 'thought', 'happy', 'could', 'live', 'love', 'must', 'admit', 'love', 'be', 'think', 'will', 'not', 'kind', 'make', 'mind', 'will', 'sweet', 'gentle', 'gentle', 'be', 'sentimental'] 0.8143805265426636\n",
      "['love', 'everywhere', 'be', 'allow', 'feel', 'hell', 'need', 'see', 'can', 'not', 'inscrutable', 'beautiful', 'try', 'try', 'try', 'head', 'do', 'not', 'know', 'be', 'stick', 'outside', 'can', 'not', 'get', 'can', 'not', 'move', 'think', 'hurt', 'know', 'pain', 'try', 'try', 'try'] 0.8134928941726685\n"
     ]
    }
   ],
   "source": [
    "new_vector = doc2vec.infer_vector(\"hate\".split())\n",
    "sims = doc_vectors.most_similar([new_vector], topn=5)\n",
    "for sim in sims:\n",
    "    print(lyrics[sim[0]], sim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chestnuts_roast', 'open', 'fire', 'jack_frost', 'nip', 'nose_yule', 'tide_carol', 'sing', 'choir', 'folk', 'dress', 'eskimos_everybody', 'knows_turkey', 'mistletoe', 'help', 'make', 'season', 'bright', 'tiny_tot', 'eye', 'aglow', 'find', 'hard', 'sleep', 'tonight', 'know', 'santa', 'way', 'loaded_lot', 'toy', 'goody', 'sleigh', 'mother', 'child', 'go', 'spy', 'see', 'reindeer', 'really', 'know', 'fly', 'be', 'offer', 'simple_phrase', 'kid', 'say', 'many', 'time', 'many', 'way', 'merry_christma'] 0.8302822709083557\n",
      "['have', 'get', 'know', 'really'] 0.8291538953781128\n",
      "['hate', 'see', 'evening', 'sun', 'go', 'hate', 'see', 'evening', 'sun', 'go', 'baby', 'go', 'leave', 'town', 'feelin', 'tomorrow', 'feel', 'today', 'be', 'feelin', 'tomorrow', 'feel', 'today', 'ill', 'pack', 'truck', 'make', 'give', 'way', 'woman', 'diamond_r', 'pull', 'man', 'around', 'be', 'not', 'man', 'love', 'would', 'go', 'nowhere', 'nowhere', 'get', 'blue', 'blue', 'man', 'get', 'heart', 'rock', 'cast', 'sea', 'else', 'would', 'not', 'go', 'far', 'love', 'baby', 'school', 'boy', 'love', 'pie', 'kentucky_colonel', 'love', 'mint_rye', 'love', 'man', 'day', 'die'] 0.825697660446167\n",
      "['lose', 'mind', 'do', 'not', 'even', 'know', 'think', 'mine', 'project', 'fear', 'inside', 'could', 'see', 'light', 'say', 'be', 'ready', 'escape', 'ill', 'shelter', 'rain', 'ill', 'pull', 'make', 'ground', 'shake', 'earthquake', 'earthquake', 'earthquake_quake', 'show', 'get', 'motherf_ck', 'beat', 'drop', 'make', 'make', 'ground', 'shake', 'earthquake', 'earthquake', 'honesty', 'sedate', 'type', 'intensity', 'hard', 'breathe', 'say', 'be', 'ready', 'escape', 'ill', 'shelter', 'rain', 'ill', 'pull', 'make', 'ground', 'shake', 'earthquake', 'say', 'be', 'ready', 'escape', 'ill', 'shelter', 'rain', 'ill', 'pull', 'make', 'ground', 'shake', 'earthquake', 'earthquake', 'earthquake', 'earthquake_quake', 'show', 'get', 'motherf_ck', 'beat', 'drop', 'make', 'make', 'ground', 'shake', 'earthquake', 'earthquake'] 0.8249520063400269\n",
      "['everyone', 'say', 'be', 'amazing', 'do', 'not', 'know', 'run', 'be', 'ble', 'be', 'run', 'run', 'know', 'need', 'can', 'not', 'live', 'alone', 'run', 'run', 'everyone', 'say', 'be', 'amazing', 'be', 'clean', 'know', 'real', 'one', 'have', 'see', 'there', 's', 'question', 'want', 'ask', 'healing', 'hear', 'everyone', 'say', 'be', 'amazing', 'anybody', 'ask', 'cry', 'sleep', 'feel', 'run', 'thinking', 'doomsday', 'get', 'let', 'go', 'run', 'run', 'pretend', 'do', 'not', 'see', 'live', 'lie', 'run', 'run', 'everyone', 'say', 'be', 'amazing', 'be', 'clean', 'know', 'real', 'one', 'have', 'see', 'there', 's', 'question', 'want', 'ask', 'heal', 'anybody', 'ask', 'know', 'be', 'real', 'amazing', 'amazing', 'amazing', 'everyone', 'say', 'be', 'amazing', 'be', 'clean', 'know', 'real', 'one', 'have', 'see', 'there', 's', 'question', 'want', 'ask', 'heal', 'everyone', 'say', 'be', 'amazing', 'everyone', 'say', 'be', 'amazing', 'want', 'always', 'feel', 'be', 'amazing', 'everyone', 'say', 'be', 'amazing', 'want', 'always', 'feel', 'be', 'amazing', 'everyone', 'say', 'be', 'amazing', 'want', 'always', 'feel', 'be', 'amazing', 'want', 'always', 'feel', 'be', 'amazing', 'be', 'amazing'] 0.8211907744407654\n"
     ]
    }
   ],
   "source": [
    "new_vector = doc2vec.infer_vector(\"god\".split())\n",
    "sims = doc_vectors.most_similar([new_vector], topn=5)\n",
    "for sim in sims:\n",
    "    print(lyrics[sim[0]], sim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['story', 'be', 'tell', 'something', 'ask', 'try', 'find', 'answer', 'see', 'sign', 'be', 'always', 'know', 'never', 'care', 'be', 'always', 'look', 'reason', 'try', 'reach', 'far', 'see', 'really', 'ask', 'try', 'find', 'answer', 'always', 'always', 'thing', 'try', 'try', 'can', 'not', 'win', 'circle', 'circle', 'spin', 'round', 'people', 'people', 'always', 'bring', 'round', 'round', 'go'] 0.8497528433799744\n",
      "['be', 'nobody', 'somebody', 'love', 'be', 'nobody', 'somebody', 'care', 'may', 'king', 'may', 'possess', 'world', 'gold', 'gold', 'will', 'not', 'bring', 'happiness', 'be', 'grow', 'old', 'world', 'still', 'will', 'never', 'change', 'sure', 'star', 'shine', 'be', 'nobody', 'somebody', 'love', 'find', 'somebody', 'love'] 0.8347553610801697\n",
      "['s', 'way', 'way', 'way', 'way', 'take', 'hand', 'tell', 'be', 'love', 'man', 'give', 'love', 'good', 'way', 'way', 'way', 'way', 'get', 'arm', 'alone', 'whisper', 'sweet', 'ear', 'turn', 'turn', 's', 'way', 'way', 'way', 'way'] 0.8342087864875793\n",
      "['purple_dusk', 'twilight', 'time', 'meadow', 'heart', 'high', 'sky', 'little', 'star', 'climb', 'always', 'remind', 'apart', 'wander', 'lane', 'far', 'away', 'leave', 'song', 'die', 'love', 'stardust', 'yesterday', 'music', 'year', 'go', 'sometimes', 'wonder', 'spend', 'lonely', 'night', 'dream', 'song', 'melody_haunt', 'reverie', 'love', 'new', 'kiss', 'inspiration', 'long', 'ago', 'consolation', 'stardust', 'song', 'garden', 'wall', 'star', 'bright', 'arm', 'nightingale_tell', 'fairytale', 'roses_grew', 'dream', 'vain', 'heart', 'remain', 'stardust_melody', 'memory', 'love', 'refrain'] 0.8341792821884155\n",
      "['say', 'would', 'not', 'stay', 'say', 'could', 'not', 'say', 'tell', 'would', 'die', 'love', 'say', 'would', 'go', 'someday', 'say', 'would', 'go', 'away', 'tell', 'would', 'dire', 'love', 'do', 'not', 'think', 'know', 'do', 'not', 'think', 'care', 'do', 'not', 'think', 'dream', 'do', 'not', 'think', 'cry', 'say', 'would', 'run', 'away', 'say', 'would', 'fly', 'away', 'tell', 'would', 'die', 'love', 'do', 'not', 'think', 'know', 'do', 'not', 'think', 'care', 'do', 'not', 'think', 'dream', 'do', 'not', 'think', 'cry'] 0.830787181854248\n"
     ]
    }
   ],
   "source": [
    "new_vector = doc2vec.infer_vector(\"dog\".split())\n",
    "sims = doc_vectors.most_similar([new_vector], topn=5)\n",
    "for sim in sims:\n",
    "    print(lyrics[sim[0]], sim[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
