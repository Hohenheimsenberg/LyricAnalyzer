{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lyrics = pd.read_csv('../dataset/Lyrics_en_clean.csv', index_col=['Band','Song'])\n",
    "genres = pd.read_csv('../dataset/artists_final_ohe.csv', index_col=['Band'])\n",
    "df = pd.merge(lyrics, genres, on=['Band'])\n",
    "del lyrics\n",
    "del genres\n",
    "\n",
    "y_train = df.drop(['Lyrics'], axis=1)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanp\\Anaconda3\\envs\\mlnd\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of doc vectors: 67565\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "doc2vec = Doc2Vec.load(\"../dataset/doc2vec\")\n",
    "doc_vectors = doc2vec.wv\n",
    "print(\"Number of doc vectors: {}\".format(len(doc_vectors.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Text_INPUT_DIM = 100\n",
    "train_size = y_train.shape[0] \n",
    "text_train_arrays = np.zeros((train_size, Text_INPUT_DIM))\n",
    "\n",
    "for i in range(train_size):\n",
    "    text_train_arrays[i] = doc2vec.docvecs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         33366600  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 64)          32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 646)               65246     \n",
      "=================================================================\n",
      "Total params: 33,529,910\n",
      "Trainable params: 33,529,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 266932 samples, validate on 66734 samples\n",
      "Epoch 1/2\n",
      "266932/266932 [==============================] - 50s 187us/step - loss: 0.0946 - acc: 0.9788 - val_loss: 0.0455 - val_acc: 0.9890\n",
      "Epoch 2/2\n",
      "266932/266932 [==============================] - 47s 177us/step - loss: 0.0451 - acc: 0.9889 - val_loss: 0.0451 - val_acc: 0.9890\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model_conv = Sequential()\n",
    "model_conv.add(Embedding(input_dim=train_size, output_dim=100))\n",
    "model_conv.add(Dropout(0.2))\n",
    "model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "model_conv.add(MaxPooling1D(pool_size=4))\n",
    "model_conv.add(LSTM(100))\n",
    "model_conv.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "model_conv.compile(loss='binary_crossentropy', optimizer='adam',    metrics=['accuracy'])\n",
    "model_conv.summary()\n",
    "\n",
    "estimator = model_conv.fit(text_train_arrays, y_train, validation_split=0.2, epochs = 2, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanp\\Anaconda3\\envs\\mlnd\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\juanp\\Anaconda3\\envs\\mlnd\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\juanp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "['bring', 'vibe', 'throw', 'air', 'air', 'air', 'run', 'hand', 'hair', 'hair', 'hair', 'give', 'love', 'rare', 'look', 'better', 'take', 'wanna', 'share', 'let', 'good', 'thing', 'go', 'waste', 'take', 'lipstick', 'face', 'wanna', 'share', 'name', 'lucy', 'put', 'lucy', 'lucifer', 'devil', 'bring', 'animal', 'right', 'name', 'lucy', 'put', 'lucy', 'lucifer', 'devil', 'bring', 'animal', 'right', 'say', 'lucy', 'say', 'yet', 'say', 'lucy', 'fix', 'something', 'real', 'real', 'tall', 'look', 'take', 'remind', 'star', 'fall', 'swear', 'love', 'last', 'name', 'ball', 'take', 'lair', 'make', 'past', 'stair', 'wanna', 'share', 'let', 'good', 'thing', 'go', 'waste', 'take', 'lipstick', 'face', 'wanna', 'share', 'name', 'lucy', 'put', 'lucy', 'lucifer', 'devil', 'bring', 'animal', 'right', 'name', 'lucy', 'put', 'lucy', 'lucifer', 'devil', 'bring', 'animal', 'right', 'say', 'lucy', 'say', 'yet', 'say', 'lucy', 'say', 'tryna', 'get', 'know', 'bite', 'tongue', 'bite', 'say', 'tryna', 'get', 'know', 'bite', 'tongue', 'bite', 'name', 'lucy', 'put', 'lucy', 'lucifer', 'devil', 'bring', 'animal', 'right', 'name', 'lucy', 'put', 'lucy', 'lucifer', 'devil', 'bring', 'animal', 'right', 'say', 'lucy', 'say', 'yet', 'say', 'lucy', 'say', 'yet', 'say', 'tryna', 'get', 'know', 'bite', 'tongue', 'bite', 'say', 'lucy', 'say', 'yet', 'say', 'tryna', 'get', 'know', 'say', 'lucy', 'say', 'yet']\n"
     ]
    }
   ],
   "source": [
    "#Bryce Fox\n",
    "#Lucy\n",
    "#genres: \"indie poptimism\",\"modern alternative rock\",\"modern rock\"\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "lyric = \"So bring your vibe over here here here \\\n",
    "Throw it up in the air air air, oh \\\n",
    "I run my hands through your hair hair hair \\\n",
    "And give you that love cuz you're oh so rare \\\n",
    "You look better over here then take you do over there \\\n",
    "And I don't wanna share \\\n",
    " \\\n",
    "You don't let a good thing go to waste \\\n",
    "So I took the lipstick off that face \\\n",
    "I don't wanna share, yeah \\\n",
    " \\\n",
    "If your name was Lucy, I'd put Lucy in her Lucifer \\\n",
    "My god, what in the devil, bring the animal right out of her \\\n",
    "If your name was Lucy, I'd put Lucy in her Lucifer \\\n",
    "My god, what in the devil, bring the animal right out of her \\\n",
    " \\\n",
    "She said she ain't Lucy \\\n",
    "I said not yet \\\n",
    "She said she ain't Lucy \\\n",
    "I'll fix you up something real real tall \\\n",
    "It's looking up, we should take it all off \\\n",
    "Yeah \\\n",
    "You remind me why the stars don't fall \\\n",
    "I swear I'll love you like your last name's Ball \\\n",
    "I'll take you to the lair if we make it past the stairs \\\n",
    "I don't wanna share, yeah \\\n",
    " \\\n",
    "You don't let a good thing go to waste \\\n",
    "So I took the lipstick off that face \\\n",
    "I don't wanna share, yeah \\\n",
    " \\\n",
    "If your name was Lucy, I'd put Lucy in her Lucifer \\\n",
    "My god, what in the devil, bring the animal right out of her \\\n",
    "If your name was Lucy, I'd put Lucy in her Lucifer \\\n",
    "My god, what in the devil, bring the animal right out of her \\\n",
    " \\\n",
    "She said she ain't Lucy \\\n",
    "I said not yet \\\n",
    "She said she ain't Lucy \\\n",
    " \\\n",
    "Said I'm just tryna get to know ya \\\n",
    "So bite your tongue before I bite it for ya \\\n",
    "Yeah \\\n",
    "Said I'm just tryna get to know ya \\\n",
    "So bite your tongue before I bite it for ya \\\n",
    " \\\n",
    "If your name was Lucy, I'd put Lucy in her Lucifer \\\n",
    "My god, what in the devil, bring the animal right out of her \\\n",
    "If your name was Lucy, I'd put Lucy in her Lucifer \\\n",
    "My god, what in the devil, bring the animal right out of her \\\n",
    " \\\n",
    "She said she ain't Lucy \\\n",
    "I said not yet \\\n",
    "She said she ain't Lucy \\\n",
    "I said not yet \\\n",
    "(Said I'm just tryna get to know ya) \\\n",
    "(So bite your tongue before I bite it for ya) \\\n",
    "She said she ain't Lucy \\\n",
    "I said not yet \\\n",
    "(Said I'm just tryna get to know ya) \\\n",
    "She said she ain't Lucy \\\n",
    "I said not yet\" \n",
    "\n",
    "lyric = simple_preprocess(str(lyric), deacc=True)\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['s', 'chorus'])\n",
    "\n",
    "new_lyric = list()\n",
    "for word in lyric:\n",
    "    if(word not in stop_words):\n",
    "        new_lyric.append(word)\n",
    "lyric = new_lyric\n",
    "\n",
    "\n",
    "# python -m spacy download en\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
    "allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "\n",
    "lemma_lyric = list()\n",
    "doc = nlp(\" \".join(lyric)) \n",
    "lemma_lyric = list()\n",
    "for token in doc:\n",
    "    if(token.pos_ in allowed_postags):\n",
    "        lemma_lyric.append(token.lemma_)\n",
    "lyric = lemma_lyric\n",
    "print(lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rock': 0.45195186,\n",
       " 'pop': 0.3405916,\n",
       " 'alternative': 0.14558189,\n",
       " 'new': 0.12430816,\n",
       " 'folk': 0.122491576,\n",
       " 'dance': 0.121637434,\n",
       " 'mellow': 0.1150324,\n",
       " 'country': 0.110866755,\n",
       " 'metal': 0.106615,\n",
       " 'wave': 0.10627294}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = np.zeros((1, Text_INPUT_DIM))\n",
    "vector[0] = doc2vec.infer_vector(lyric)\n",
    "y_pred = model_conv.predict(vector)\n",
    "idx = (-y_pred[0]).argsort()[:10]\n",
    "dict(zip(y_train.columns.values[idx],y_pred[0][idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
